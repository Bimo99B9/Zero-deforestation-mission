{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importing modules \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1714, 332, 332, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(635, 332, 332, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "shape = (332,332)\n",
    "\n",
    "# Process training data.\n",
    "train_images = []\n",
    "train_path = df_train[\"example_path\"].to_numpy()\n",
    "\n",
    "for filename in train_path:\n",
    "    img = cv2.imread(filename)\n",
    "    img = cv2.resize(img, shape)\n",
    "\n",
    "    sigma = 0.33\n",
    "    v = np.median(img)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    canny_edge = cv2.Canny(img, lower, upper)\n",
    "\n",
    "    img = cv2.applyColorMap(canny_edge, cv2.COLORMAP_PINK)\n",
    "\n",
    "    train_images.append(img)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "\n",
    "\n",
    "# Process test data.\n",
    "test_images = []\n",
    "test_path = df_test[\"example_path\"].to_numpy()\n",
    "\n",
    "for filename in test_path:\n",
    "    img = cv2.imread(filename)\n",
    "    img = cv2.resize(img, shape)\n",
    "\n",
    "    sigma = 0.33\n",
    "    v = np.median(img)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    canny_edge = cv2.Canny(img, lower, upper)\n",
    "\n",
    "    img = cv2.applyColorMap(canny_edge, cv2.COLORMAP_PINK)\n",
    "\n",
    "    test_images.append(img)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "display(train_images.shape)\n",
    "display(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "df_train_label = df_train.pop(\"label\")\n",
    "df_train_label = pd.get_dummies(df_train_label).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_images, df_train_label, random_state=1234, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_examples_train = X_train.shape[0]\n",
    "num_examples_val = X_val.shape[0]\n",
    "display(num_examples_train)\n",
    "display(num_examples_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, batch_size=64, shuffle_buffer_size=1000):\n",
    "  if cache:\n",
    "    if isinstance(cache, str):\n",
    "      ds = ds.cache(cache)\n",
    "    else:\n",
    "      ds = ds.cache()\n",
    "  #ds = ds.map(lambda d: (d[\"image\"], tf.one_hot(d[\"label\"], num_classes)))\n",
    "  # shuffle the dataset\n",
    "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "  # Repeat forever\n",
    "  ds = ds.repeat()\n",
    "  # split to batches\n",
    "  ds = ds.batch(batch_size)\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# preprocess training & validation sets\n",
    "train_ds = prepare_for_training(train_ds, batch_size=batch_size)\n",
    "valid_ds = prepare_for_training(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 332, 332, 3) (1, 3)\n",
      "(1, 332, 332, 3) (1, 3)\n"
     ]
    }
   ],
   "source": [
    "# validating shapes\n",
    "for el in valid_ds.take(1):\n",
    "  print(el[0].shape, el[1].shape)\n",
    "for el in train_ds.take(1):\n",
    "  print(el[0].shape, el[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first batch of the training set\n",
    "batch = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(batch):\n",
    "  plt.figure(figsize=(16, 16))\n",
    "  for n in range(min(32, batch_size)):\n",
    "      ax = plt.subplot(batch_size//8, 8, n + 1)\n",
    "      # show the image\n",
    "      plt.imshow(batch[0][n])\n",
    "      # and put the corresponding label as title upper to the image\n",
    "      #plt.title(class_names[tf.argmax(batch[1][n].numpy())])\n",
    "      plt.axis('off')\n",
    "      plt.savefig(\"sample-images.png\")\n",
    "\n",
    "# showing a batch of images along with labels\n",
    "#show_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_l/feature_vector/2\"\n",
    "\n",
    "# download & load the layer as a feature vector\n",
    "output_size = batch_size*3*2\n",
    "keras_layer = hub.KerasLayer(model_url, output_shape=[output_size], trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.Sequential([\n",
    "  keras_layer,\n",
    "  tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "# build the model with input image shape as (64, 64, 3)\n",
    "m.build([None, 332, 332, 3])\n",
    "m.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\", tfa.metrics.F1Score(num_classes)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              117746848 \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 117,750,691\n",
      "Trainable params: 117,238,115\n",
      "Non-trainable params: 512,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"zero-deforestation-classification\"\n",
    "model_path = os.path.join(\"results\", model_name + \".h5\")\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path, save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training & validation steps since we're using .repeat() on our dataset\n",
    "# number of training steps\n",
    "n_training_steps   = int(num_examples_train) // (batch_size)\n",
    "# number of validation steps\n",
    "n_validation_steps = int(num_examples_val) // (batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1542/1542 [==============================] - 333s 189ms/step - loss: 0.9918 - accuracy: 0.4702 - f1_score: 0.3092 - val_loss: 30.4558 - val_accuracy: 0.3198 - val_f1_score: 0.2328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 30.45578, saving model to results\\zero-deforestation-classification.h5\n",
      "Epoch 2/5\n",
      "1542/1542 [==============================] - 287s 186ms/step - loss: 0.9891 - accuracy: 0.4650 - f1_score: 0.2802 - val_loss: 1.1212 - val_accuracy: 0.5523 - val_f1_score: 0.3581\n",
      "\n",
      "Epoch 00002: val_loss improved from 30.45578 to 1.12121, saving model to results\\zero-deforestation-classification.h5\n",
      "Epoch 3/5\n",
      "1542/1542 [==============================] - 287s 186ms/step - loss: 0.9866 - accuracy: 0.4760 - f1_score: 0.2878 - val_loss: 2.1486 - val_accuracy: 0.3488 - val_f1_score: 0.3411\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.12121\n",
      "Epoch 4/5\n",
      "1542/1542 [==============================] - 287s 186ms/step - loss: 0.9808 - accuracy: 0.4916 - f1_score: 0.3074 - val_loss: 6.6438 - val_accuracy: 0.4477 - val_f1_score: 0.3119\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.12121\n",
      "Epoch 5/5\n",
      "1542/1542 [==============================] - 323s 210ms/step - loss: 0.9815 - accuracy: 0.4630 - f1_score: 0.2763 - val_loss: 3.6666 - val_accuracy: 0.5523 - val_f1_score: 0.2372\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.12121\n"
     ]
    }
   ],
   "source": [
    "history = m.fit(\n",
    "    train_ds, validation_data=valid_ds,\n",
    "    steps_per_epoch=n_training_steps,\n",
    "    validation_steps=n_validation_steps,\n",
    "    verbose=1, epochs=5, \n",
    "    callbacks=[model_checkpoint]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73e357180c10748ca7d4f3a1ac37ad0bc94f0b7537594ff0b43acb32581eda9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
